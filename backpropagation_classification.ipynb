{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "efh0Vbd75p02"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qsjhE0IG5qy5"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Z9vKYUso5y3F",
        "outputId": "921e5023-3af8-4552-d541-13371dd8655d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cgpa</th>\n",
              "      <th>profile_score</th>\n",
              "      <th>placed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cgpa  profile_score  placed\n",
              "0     8              8       1\n",
              "1     7              9       1\n",
              "2     6             10       0\n",
              "3     5              5       0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BSAs5N7L5z9f"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "\n",
        "  np.random.seed(3)\n",
        "  parameters = {}\n",
        "  L = len(layer_dims)\n",
        "\n",
        "  for l in range(1, L):\n",
        "\n",
        "    parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n",
        "    parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "\n",
        "  return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VDwatKWP543L"
      },
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "def sigmoid(Z):\n",
        "\n",
        "  A = 1/(1+np.exp(-Z))\n",
        "\n",
        "  return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q7Pqn3Le6W88"
      },
      "outputs": [],
      "source": [
        "def linear_forward(A_prev, W, b):\n",
        "\n",
        "  Z = np.dot(W.T, A_prev) + b\n",
        "\n",
        "  A = sigmoid(Z)\n",
        "\n",
        "  return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VkUO9wdf6gXj"
      },
      "outputs": [],
      "source": [
        "# L-layer feed forward\n",
        "\n",
        "def L_layer_forward(X, parameters):\n",
        "\n",
        "  A = X\n",
        "  L = len(parameters) // 2                  # number of layers in the neural network\n",
        "\n",
        "  for l in range(1, L+1):\n",
        "    A_prev = A\n",
        "    Wl = parameters['W' + str(l)]\n",
        "    bl = parameters['b' + str(l)]\n",
        "    #print(\"A\"+str(l-1)+\": \", A_prev)\n",
        "    #print(\"W\"+str(l)+\": \", Wl)\n",
        "    #print(\"b\"+str(l)+\": \", bl)\n",
        "    #print(\"--\"*20)\n",
        "\n",
        "    A = linear_forward(A_prev, Wl, bl)\n",
        "    #print(\"A\"+str(l)+\": \", A)\n",
        "    #print(\"**\"*20)\n",
        "\n",
        "  return A,A_prev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NKBtskel6jsf"
      },
      "outputs": [],
      "source": [
        "def update_parameters(parameters,y,y_hat,A1,X):\n",
        "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n",
        "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n",
        "  parameters['b2'][0][0] = parameters['b2'][0][0] + (0.0001 * (y - y_hat))\n",
        "\n",
        "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
        "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
        "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
        "\n",
        "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
        "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
        "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRuFdbwf7uDz",
        "outputId": "ca7ef719-95c0-4e5f-fcf4-6bf3d30f76c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for this student -  0.613402628898913\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.10000513, 0.10000513],\n",
              "        [0.10000513, 0.10000513]]),\n",
              " 'b1': array([[6.41054186e-07],\n",
              "        [6.41054186e-07]]),\n",
              " 'W2': array([[0.10003815],\n",
              "        [0.10003815]]),\n",
              " 'b2': array([[4.5849481e-05]])}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "y = df[['placed']].values[0][0]\n",
        "\n",
        "# Parameter initialization\n",
        "parameters = initialize_parameters([2,2,1])\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]\n",
        "\n",
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "\n",
        "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHTFMij_8zJc",
        "outputId": "95e49589-f2a7-4451-98f2-04a5d2aa753a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for this student -  0.6133514436691428\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.10000962, 0.1000109 ],\n",
              "        [0.10000962, 0.1000109 ]]),\n",
              " 'b1': array([[1.28227883e-06],\n",
              "        [1.28227883e-06]]),\n",
              " 'W2': array([[0.10007629],\n",
              "        [0.10007629]]),\n",
              " 'b2': array([[9.16961903e-05]])}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "y = df[['placed']].values[1][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]\n",
        "\n",
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "\n",
        "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZCtTGoI90Jb",
        "outputId": "57944af6-ce79-4ad7-eea0-7576e788badb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for this student -  0.7799272184937318\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.10000507, 0.10000333],\n",
              "        [0.10000507, 0.10000333]]),\n",
              " 'b1': array([[5.25214767e-07],\n",
              "        [5.25225084e-07]]),\n",
              " 'W2': array([[0.10003123],\n",
              "        [0.10003123]]),\n",
              " 'b2': array([[3.75401279e-05]])}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df[['cgpa', 'profile_score']].values[2].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "y = df[['placed']].values[2][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]\n",
        "\n",
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "\n",
        "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvIOVb8j94zz",
        "outputId": "6bda9dd3-38bd-4021-cd03-9f02c526e8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for this student -  0.7689684329362058\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.0999998 , 0.09999806],\n",
              "        [0.0999998 , 0.09999806]]),\n",
              " 'b1': array([[-5.29516797e-07],\n",
              "        [-5.29514990e-07]]),\n",
              " 'W2': array([[0.09999201],\n",
              "        [0.09999201]]),\n",
              " 'b2': array([[-1.61107777e-05]])}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "y = df[['placed']].values[3][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]\n",
        "\n",
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "\n",
        "print('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RTy2Hsy9-M7",
        "outputId": "774328a3-5614-4a66-8dac-425a271319b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch -  1 Loss -  0.6939124309994983\n",
            "Epoch -  2 Loss -  0.6939114509742006\n",
            "Epoch -  3 Loss -  0.6939104713855384\n",
            "Epoch -  4 Loss -  0.6939094922333021\n",
            "Epoch -  5 Loss -  0.6939085135172819\n",
            "Epoch -  6 Loss -  0.6939075352372682\n",
            "Epoch -  7 Loss -  0.6939065573930516\n",
            "Epoch -  8 Loss -  0.6939055799844227\n",
            "Epoch -  9 Loss -  0.6939046030111722\n",
            "Epoch -  10 Loss -  0.693903626473091\n",
            "Epoch -  11 Loss -  0.6939026503699699\n",
            "Epoch -  12 Loss -  0.6939016747016002\n",
            "Epoch -  13 Loss -  0.6939006994677729\n",
            "Epoch -  14 Loss -  0.6938997246682792\n",
            "Epoch -  15 Loss -  0.6938987503029107\n",
            "Epoch -  16 Loss -  0.6938977763714584\n",
            "Epoch -  17 Loss -  0.6938968028737142\n",
            "Epoch -  18 Loss -  0.6938958298094697\n",
            "Epoch -  19 Loss -  0.6938948571785166\n",
            "Epoch -  20 Loss -  0.6938938849806471\n",
            "Epoch -  21 Loss -  0.6938929132156526\n",
            "Epoch -  22 Loss -  0.6938919418833256\n",
            "Epoch -  23 Loss -  0.6938909709834581\n",
            "Epoch -  24 Loss -  0.6938900005158424\n",
            "Epoch -  25 Loss -  0.6938890304802711\n",
            "Epoch -  26 Loss -  0.6938880608765363\n",
            "Epoch -  27 Loss -  0.6938870917044309\n",
            "Epoch -  28 Loss -  0.6938861229637474\n",
            "Epoch -  29 Loss -  0.6938851546542789\n",
            "Epoch -  30 Loss -  0.6938841867758179\n",
            "Epoch -  31 Loss -  0.6938832193281578\n",
            "Epoch -  32 Loss -  0.6938822523110912\n",
            "Epoch -  33 Loss -  0.6938812857244119\n",
            "Epoch -  34 Loss -  0.6938803195679129\n",
            "Epoch -  35 Loss -  0.6938793538413872\n",
            "Epoch -  36 Loss -  0.6938783885446289\n",
            "Epoch -  37 Loss -  0.6938774236774317\n",
            "Epoch -  38 Loss -  0.693876459239589\n",
            "Epoch -  39 Loss -  0.6938754952308946\n",
            "Epoch -  40 Loss -  0.6938745316511425\n",
            "Epoch -  41 Loss -  0.6938735685001267\n",
            "Epoch -  42 Loss -  0.6938726057776414\n",
            "Epoch -  43 Loss -  0.6938716434834808\n",
            "Epoch -  44 Loss -  0.6938706816174391\n",
            "Epoch -  45 Loss -  0.6938697201793111\n",
            "Epoch -  46 Loss -  0.6938687591688908\n",
            "Epoch -  47 Loss -  0.6938677985859731\n",
            "Epoch -  48 Loss -  0.693866838430353\n",
            "Epoch -  49 Loss -  0.6938658787018248\n",
            "Epoch -  50 Loss -  0.6938649194001839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'W1': array([[0.09999042, 0.09990338],\n",
              "        [0.09999049, 0.0999034 ]]),\n",
              " 'b1': array([[-2.63694652e-05],\n",
              "        [-2.63678488e-05]]),\n",
              " 'W2': array([[0.09960344],\n",
              "        [0.09960349]]),\n",
              " 'b2': array([[-0.00080196]])}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# epochs implementation\n",
        "\n",
        "parameters = initialize_parameters([2,2,1])\n",
        "epochs = 50\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  Loss = []\n",
        "\n",
        "  for j in range(df.shape[0]):\n",
        "\n",
        "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "    y = df[['placed']].values[j][0]\n",
        "\n",
        "    # Parameter initialization\n",
        "\n",
        "\n",
        "    y_hat,A1 = L_layer_forward(X,parameters)\n",
        "    y_hat = y_hat[0][0]\n",
        "\n",
        "    update_parameters(parameters,y,y_hat,A1,X)\n",
        "\n",
        "    Loss.append(-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n",
        "\n",
        "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Keras implementation of above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nkBltTUj-M_g"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/llm/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-01-05 01:01:26.608117: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
            "2025-01-05 01:01:26.608212: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
            "2025-01-05 01:01:26.608242: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
            "2025-01-05 01:01:26.608655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-01-05 01:01:26.608680: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid', input_dim=2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 1.0921215 ,  0.5500517 ],\n",
              "        [ 0.8142363 , -0.17195177]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.19367349],\n",
              "        [1.3677801 ]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_weights = [np.array([[0.1,0.1],[0.1,0.1]], \n",
        "                    dtype='float32'), \n",
        "                np.array([0.,0.], \n",
        "                    dtype='float32'), \n",
        "                np.array([[0.1],[0.1]], \n",
        "                    dtype='float32'), \n",
        "                np.array([0.], \n",
        "                    dtype='float32')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0.1, 0.1],\n",
              "        [0.1, 0.1]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.1],\n",
              "        [0.1]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.set_weights(new_weights)\n",
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-05 01:06:50.199117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6716\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7305 \n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6567 \n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6733 \n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6837 \n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6715 \n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7303 \n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7066 \n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7303 \n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6837 \n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6561 \n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6568 \n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7302 \n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7324 \n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7065 \n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7065 \n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7065 \n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7168  \n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7065 \n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6569 \n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6716 \n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7135 \n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7065 \n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6735 \n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7167 \n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6837 \n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7167 \n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6827 \n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6827 \n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7299 \n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6571 \n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7166 \n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6735 \n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7298 \n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7064 \n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6827 \n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7319 \n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7063 \n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7318 \n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7024 \n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7063 \n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7296 \n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7063 \n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6718 \n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6736 \n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7063 \n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6838 \n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6566 \n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7063 \n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7317 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1360ae380>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(df.iloc[:,0:-1].values, df['placed'].values, epochs=50, verbose=1, batch_size=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
